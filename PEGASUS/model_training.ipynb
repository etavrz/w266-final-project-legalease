{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pegasus Training on Bill-117 Dataset"
      ],
      "metadata": {
        "id": "UlxKsGmnXvG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Mw3Bh4NlU87h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E4zTGC32Wy6",
        "outputId": "d08b8ae8-34ee-43c7-a3aa-7a33d93ae044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBRVqkMU64Hv"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets evaluate accelerate peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWbnUNyO6119"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq, PegasusTokenizer, PegasusForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from huggingface_hub import notebook_login\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import torch\n",
        "import os\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL4Br-NW7IK1"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/colab-notebooks/w266/hf.txt\", \"r\") as f:\n",
        "    HF_TOKEN = f.read()\n",
        "    os.environ[\"HF_TOKEN\"] = HF_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== ENVIRONMENT ======\n",
        "DEV = False\n",
        "EXPLORE = False\n",
        "PEFT = False\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# ====== DATA =======\n",
        "INPUT_MAX_LENGTH = 512\n",
        "LABEL_MAX_LENGTH = 128\n",
        "INPUT_COLUMN = \"cur_text\"\n",
        "LABEL_COLUMN = \"cleaned_summary\"\n",
        "\n",
        "# ====== MODEL ======\n",
        "CHECKPOINT = \"google/pegasus-xsum\"\n",
        "PATH = '/content/drive/MyDrive/colab-notebooks/w266/'\n",
        "if PEFT:\n",
        "  MODEL_NAME = \"pegasus-lora-legalease\"\n",
        "else:\n",
        "  MODEL_NAME = \"pegasus-legalease\"\n",
        "HUGGINGFACE_DIR = \"etav22/\" + MODEL_NAME\n",
        "CUSTOM_NAME = \"pegasus-baseline-128\"\n",
        "\n",
        "# ====== OPTIIZER =======\n",
        "OPTIMIZER = \"adamw_torch\"\n",
        "LEARNING_RATE = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# ====== TRAINING ======\n",
        "EVAL_STRATEGY = \"steps\"\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 2\n",
        "SAVE_STEPS = 100 if DEV else 1000\n",
        "EVAL_STEPS = 100 if DEV else 250\n",
        "LOGGING_STEPS = 100 if DEV else 500\n",
        "EARLY_STOPPING_PATIENCE = 3\n",
        "EARLY_STOPPING_THRESHOLD = 0.005\n",
        "\n",
        "print(f\"Using {CHECKPOINT} model\")\n",
        "print(f\"Column names: {INPUT_COLUMN}, {LABEL_COLUMN}\")\n",
        "print(f\"Model name: {MODEL_NAME}\")\n",
        "print(f\"Custom name: {CUSTOM_NAME}\")"
      ],
      "metadata": {
        "id": "f4fgYB1_KJOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc07b58-55ed-4079-c19e-c942cde75ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using google/pegasus-xsum model\n",
            "Column names: cur_text, cleaned_summary\n",
            "Model name: pegasus-legalease\n",
            "Custom name: pegasus-baseline-128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset setup"
      ],
      "metadata": {
        "id": "coerUAv80hvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/colab-notebooks/w266/data_v3\n",
        "!git clone https://huggingface.co/datasets/jordanfan/processed_us_congress_117_bills_v3 /content/drive/MyDrive/colab-notebooks/w266/data_v3"
      ],
      "metadata": {
        "id": "oWDoGoL422NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22588579-5274-4391-90fa-db2f65e1f7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/colab-notebooks/w266/data_v3' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"/content/drive/MyDrive/colab-notebooks/w266/data_v3/data\")\n",
        "dataset['train']"
      ],
      "metadata": {
        "id": "I8A6LWWo2_el",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031722ab-6c77-486d-fd69-e39c5cf020d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'index', 'id', 'policy_areas', 'cur_summary', 'cur_text', 'title', 'titles_official', 'titles_short', 'sponsor_name', 'sponsor_party', 'sponsor_state', 'cleaned_summary', 'extracted_text', 'extracted_text_375', 'extracted_text_750', 'extracted_text_1000', 'bertsum_extracted_250', 'bertsum_extracted_375', 'bertsum_extracted_375_1000', 'bertsum_extracted_250_1000', 'bertsum_extracted_375_750', 'bertsum_extracted_250_750', 'bertsum_extracted_375_500', 'bertsum_extracted_250_500', 'bertsum_extracted_375_375', 'bertsum_extracted_250_375'],\n",
              "    num_rows: 11277\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWpTUu4x612B"
      },
      "source": [
        "## Pegasus Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbfCfexE612B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91c5413-fad6-4108-c489-0ee4d0bf5aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PegasusConfig {\n",
              "  \"_name_or_path\": \"google/pegasus-xsum\",\n",
              "  \"activation_dropout\": 0.1,\n",
              "  \"activation_function\": \"relu\",\n",
              "  \"add_bias_logits\": false,\n",
              "  \"add_final_layer_norm\": true,\n",
              "  \"architectures\": [\n",
              "    \"PegasusForConditionalGeneration\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classif_dropout\": 0.0,\n",
              "  \"classifier_dropout\": 0.0,\n",
              "  \"d_model\": 1024,\n",
              "  \"decoder_attention_heads\": 16,\n",
              "  \"decoder_ffn_dim\": 4096,\n",
              "  \"decoder_layerdrop\": 0.0,\n",
              "  \"decoder_layers\": 16,\n",
              "  \"decoder_start_token_id\": 0,\n",
              "  \"do_blenderbot_90_layernorm\": false,\n",
              "  \"dropout\": 0.1,\n",
              "  \"encoder_attention_heads\": 16,\n",
              "  \"encoder_ffn_dim\": 4096,\n",
              "  \"encoder_layerdrop\": 0.0,\n",
              "  \"encoder_layers\": 16,\n",
              "  \"eos_token_id\": 1,\n",
              "  \"extra_pos_embeddings\": 0,\n",
              "  \"force_bos_token_to_be_generated\": false,\n",
              "  \"forced_eos_token_id\": 1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"init_std\": 0.02,\n",
              "  \"is_encoder_decoder\": true,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"length_penalty\": 0.6,\n",
              "  \"max_length\": 128,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"pegasus\",\n",
              "  \"normalize_before\": true,\n",
              "  \"normalize_embedding\": false,\n",
              "  \"num_beams\": 4,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"scale_embedding\": true,\n",
              "  \"static_position_embeddings\": true,\n",
              "  \"transformers_version\": \"4.38.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 96103\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenizer = PegasusTokenizer.from_pretrained(CHECKPOINT)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(CHECKPOINT)\n",
        "model.config.max_length = LABEL_MAX_LENGTH\n",
        "model.config.num_beams = 4\n",
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "5_QdzxznXmrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11Bw97NB612C"
      },
      "outputs": [],
      "source": [
        "# Tokenize the entire dataset\n",
        "def tokenize_function(examples):\n",
        "\tmodel_inputs = tokenizer(examples[INPUT_COLUMN], return_tensors=\"pt\", max_length=INPUT_MAX_LENGTH, padding=True, truncation=True)\n",
        "\tlabels = tokenizer(text_target=examples[LABEL_COLUMN], max_length=LABEL_MAX_LENGTH, padding=True, truncation=True)\n",
        "\tmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "\treturn model_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "kLbxzPCqXeoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peft Configuration"
      ],
      "metadata": {
        "id": "0EPNWbSxZ_6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_target_modules(model):\n",
        "    # Initialize a Set to Store Unique Layers\n",
        "    unique_layers = set()\n",
        "\n",
        "    # Iterate Over All Named Modules in the Model\n",
        "    for name, module in model.named_modules():\n",
        "        # Check if the Module Type Contains 'Linear4bit'\n",
        "        if \"Linear\" in str(type(module)):\n",
        "            # Extract the Type of the Layer\n",
        "            layer_type = name.split('.')[-1]\n",
        "\n",
        "            # Add the Layer Type to the Set of Unique Layers\n",
        "            unique_layers.add(layer_type)\n",
        "\n",
        "    # Return the Set of Unique Layers Converted to a List\n",
        "    return list(unique_layers)\n",
        "\n",
        "modules = find_target_modules(model)\n",
        "print(modules)"
      ],
      "metadata": {
        "id": "Ay5xkVxgqwsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fa7a52-6116-44dd-d129-a45458a6a39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['out_proj', 'lm_head', 'fc1', 'fc2', 'v_proj', 'q_proj', 'k_proj']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if PEFT:\n",
        "  peft_config = LoraConfig(\n",
        "      task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "      inference_mode=False,\n",
        "      target_modules=modules,\n",
        "      r=16,\n",
        "      lora_alpha=32,\n",
        "      lora_dropout=0.1\n",
        "  )\n",
        "\n",
        "  model = get_peft_model(model, peft_config)\n",
        "  model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "KRPhSGX9aNG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Configurations"
      ],
      "metadata": {
        "id": "68Jmb9kOaGWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE, early_stopping_threshold=EARLY_STOPPING_THRESHOLD)"
      ],
      "metadata": {
        "id": "cGXUxrH6W2Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=HUGGINGFACE_DIR,\n",
        "    evaluation_strategy=EVAL_STRATEGY,\n",
        "    save_strategy=EVAL_STRATEGY,\n",
        "    save_steps=SAVE_STEPS,\n",
        "    eval_steps=EVAL_STEPS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    num_train_epochs=EPOCHS,\n",
        "    fp16=True,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    push_to_hub=True,\n",
        "    hub_token=HF_TOKEN\n",
        ")"
      ],
      "metadata": {
        "id": "S0CQXPlUN4dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoDQAxFS8B7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "6a52af75-f19b-42f2-df81-225652ba0ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='5640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/5640 1:21:39 < 41:10, 0.76 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.995386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.259200</td>\n",
              "      <td>4.317471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>5.259200</td>\n",
              "      <td>1.307422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.381900</td>\n",
              "      <td>1.198699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>2.381900</td>\n",
              "      <td>1.167780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.311300</td>\n",
              "      <td>1.149074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>1.311300</td>\n",
              "      <td>1.136877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.215800</td>\n",
              "      <td>1.127331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>1.215800</td>\n",
              "      <td>1.116548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.211900</td>\n",
              "      <td>1.113659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>1.211900</td>\n",
              "      <td>1.114723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.230700</td>\n",
              "      <td>1.120959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>1.230700</td>\n",
              "      <td>1.124603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.210700</td>\n",
              "      <td>1.126922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>1.210700</td>\n",
              "      <td>1.137239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 128, 'num_beams': 4, 'length_penalty': 0.6, 'forced_eos_token_id': 1}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 128, 'num_beams': 4, 'length_penalty': 0.6, 'forced_eos_token_id': 1}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 128, 'num_beams': 4, 'length_penalty': 0.6, 'forced_eos_token_id': 1}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3750, training_loss=1.922697998046875, metrics={'train_runtime': 4901.8577, 'train_samples_per_second': 4.601, 'train_steps_per_second': 1.151, 'total_flos': 2.166664890993869e+16, 'train_loss': 1.922697998046875, 'epoch': 1.33})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    callbacks = [early_stopping]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Model"
      ],
      "metadata": {
        "id": "FI80mCUio9Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.create_model_card(\n",
        "    language='english',\n",
        "    model_name=MODEL_NAME,\n",
        "    finetuned_from=CHECKPOINT,\n",
        "    tasks='summarization',\n",
        "    tags='summarization',\n",
        "    dataset='hheiden/us-congress-117-bills',\n",
        "    dataset_args=f\"Max token input: {INPUT_MAX_LENGTH} | {LABEL_MAX_LENGTH}\"\n",
        ")"
      ],
      "metadata": {
        "id": "dHrDXfrRK9VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DEV:\n",
        "  commit_msg = f\"training completed[dev]: {CUSTOM_NAME}\"\n",
        "else:\n",
        "  commit_msg = f\"training completed[prod]: {CUSTOM_NAME}\"\n",
        "\n",
        "trainer.push_to_hub(commit_message=commit_msg)"
      ],
      "metadata": {
        "id": "U4Jr1gpHIZYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "c88e9bc0449d439d857831fe6bf44862",
            "ca4e9dd4b3994e58aaaed51a8a40067e",
            "eec8eabe03734709ad14fd371681b752",
            "c92773470b964180992cac0f129032be",
            "37af9c0ebeb24aa9bbc037b232adf01e",
            "79b4a010ba16439c868949f663ca5ba5",
            "4dbdc994165e47e48a9a5ee71371a31e",
            "c0a3f1f33bdd47308fa45f9661550c42",
            "023e8b2ffcc54e99a6f45221f92c524c",
            "259f4c841cbf4655931881caad8f14b9",
            "0297dc684f1e404b947ce7341e2ee496"
          ]
        },
        "outputId": "e5c8b96d-baec-4ea1-c022-f286eda11588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 128, 'num_beams': 4, 'length_penalty': 0.6, 'forced_eos_token_id': 1}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1712346352.9e6d5516626c.3600.0:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c88e9bc0449d439d857831fe6bf44862"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/etav22/pegasus-legalease/commit/c9dc406239283b65e173ccd7c915dabe141d5ea9', commit_message='training completed[prod]: pegasus-baseline-128', commit_description='', oid='c9dc406239283b65e173ccd7c915dabe141d5ea9', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Mi-9NHai611_",
        "0EPNWbSxZ_6F"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c88e9bc0449d439d857831fe6bf44862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca4e9dd4b3994e58aaaed51a8a40067e",
              "IPY_MODEL_eec8eabe03734709ad14fd371681b752",
              "IPY_MODEL_c92773470b964180992cac0f129032be"
            ],
            "layout": "IPY_MODEL_37af9c0ebeb24aa9bbc037b232adf01e"
          }
        },
        "ca4e9dd4b3994e58aaaed51a8a40067e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b4a010ba16439c868949f663ca5ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbdc994165e47e48a9a5ee71371a31e",
            "value": "events.out.tfevents.1712346352.9e6d5516626c.3600.0: 100%"
          }
        },
        "eec8eabe03734709ad14fd371681b752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a3f1f33bdd47308fa45f9661550c42",
            "max": 11404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_023e8b2ffcc54e99a6f45221f92c524c",
            "value": 11404
          }
        },
        "c92773470b964180992cac0f129032be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259f4c841cbf4655931881caad8f14b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0297dc684f1e404b947ce7341e2ee496",
            "value": " 11.4k/11.4k [00:00&lt;00:00, 79.1kB/s]"
          }
        },
        "37af9c0ebeb24aa9bbc037b232adf01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b4a010ba16439c868949f663ca5ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbdc994165e47e48a9a5ee71371a31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0a3f1f33bdd47308fa45f9661550c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023e8b2ffcc54e99a6f45221f92c524c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "259f4c841cbf4655931881caad8f14b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0297dc684f1e404b947ce7341e2ee496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}